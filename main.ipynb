{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\2\\ipykernel_6060\\3824390472.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  full_data['Working_Hours'] = (pd.to_datetime(full_data['Time_End']) - pd.to_datetime(full_data['Time_Start'])).dt.seconds / 3600\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\2\\ipykernel_6060\\3824390472.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  full_data['Working_Hours'] = (pd.to_datetime(full_data['Time_End']) - pd.to_datetime(full_data['Time_Start'])).dt.seconds / 3600\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.read_csv(\"ourdata.csv\")\n",
    "\n",
    "# Feature engineering\n",
    "# Convert 'Date' to datetime and extract useful features\n",
    "full_data['Date'] = pd.to_datetime(full_data['Date'])\n",
    "full_data['Day_of_Week'] = full_data['Date'].dt.dayofweek\n",
    "full_data['Month'] = full_data['Date'].dt.month\n",
    "full_data['Working_Hours'] = (pd.to_datetime(full_data['Time_End']) - pd.to_datetime(full_data['Time_Start'])).dt.seconds / 3600\n",
    "\n",
    "# Select features and target\n",
    "X = full_data[['Day_of_Week', 'Month', 'Working_Hours', 'Crop_Type', 'Base_Hourly_Wage', 'Supply_Demand_Ratio', 'Dynamic_Pricing_Multiplier']]\n",
    "y = full_data['Total_Earnings']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['Day_of_Week', 'Month', 'Working_Hours', 'Base_Hourly_Wage', 'Supply_Demand_Ratio', 'Dynamic_Pricing_Multiplier']\n",
    "categorical_features = ['Crop_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model = MLPRegressor(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter=500, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', ann_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;Day_of_Week&#x27;, &#x27;Month&#x27;,\n",
       "                                                   &#x27;Working_Hours&#x27;,\n",
       "                                                   &#x27;Base_Hourly_Wage&#x27;,\n",
       "                                                   &#x27;Supply_Demand_Ratio&#x27;,\n",
       "                                                   &#x27;Dynamic_Pricing_Multiplier&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;Crop_Type&#x27;])])),\n",
       "                (&#x27;model&#x27;, MLPRegressor(max_iter=500, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;Day_of_Week&#x27;, &#x27;Month&#x27;,\n",
       "                                                   &#x27;Working_Hours&#x27;,\n",
       "                                                   &#x27;Base_Hourly_Wage&#x27;,\n",
       "                                                   &#x27;Supply_Demand_Ratio&#x27;,\n",
       "                                                   &#x27;Dynamic_Pricing_Multiplier&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;Crop_Type&#x27;])])),\n",
       "                (&#x27;model&#x27;, MLPRegressor(max_iter=500, random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;Day_of_Week&#x27;, &#x27;Month&#x27;, &#x27;Working_Hours&#x27;,\n",
       "                                  &#x27;Base_Hourly_Wage&#x27;, &#x27;Supply_Demand_Ratio&#x27;,\n",
       "                                  &#x27;Dynamic_Pricing_Multiplier&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(), [&#x27;Crop_Type&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">num</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Day_of_Week&#x27;, &#x27;Month&#x27;, &#x27;Working_Hours&#x27;, &#x27;Base_Hourly_Wage&#x27;, &#x27;Supply_Demand_Ratio&#x27;, &#x27;Dynamic_Pricing_Multiplier&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Crop_Type&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MLPRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPRegressor.html\">?<span>Documentation for MLPRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MLPRegressor(max_iter=500, random_state=42)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['Day_of_Week', 'Month',\n",
       "                                                   'Working_Hours',\n",
       "                                                   'Base_Hourly_Wage',\n",
       "                                                   'Supply_Demand_Ratio',\n",
       "                                                   'Dynamic_Pricing_Multiplier']),\n",
       "                                                 ('cat', OneHotEncoder(),\n",
       "                                                  ['Crop_Type'])])),\n",
       "                ('model', MLPRegressor(max_iter=500, random_state=42))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08925771735435657, 0.9996523898513691)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ann_model.pkl'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Export the trained model to a file using pickle\n",
    "pickle_model_path = \"ann_model.pkl\"\n",
    "with open(pickle_model_path, 'wb') as file:\n",
    "    pickle.dump(pipeline, file)\n",
    "\n",
    "pickle_model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137.84203414]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Example new input data\n",
    "new_data = {\n",
    "    'Day_of_Week': [2],  # Tuesday\n",
    "    'Month': [1],  # January\n",
    "    'Working_Hours': [8],  # 8 hours\n",
    "    'Crop_Type': ['Wheat'],  # Crop type\n",
    "    'Base_Hourly_Wage': [12.00],  # Base hourly wage\n",
    "    'Supply_Demand_Ratio': [1.2],  # Supply-demand ratio\n",
    "    'Dynamic_Pricing_Multiplier': [1.44]  # Dynamic pricing multiplier\n",
    "}\n",
    "\n",
    "# Convert the new input data into a DataFrame\n",
    "new_input_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Load the trained model from the file\n",
    "with open('ann_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predicted_earnings = loaded_model.predict(new_input_df)\n",
    "\n",
    "# Output the prediction\n",
    "print(predicted_earnings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (2171861709.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[21], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Mean Squared Error (MSE) = 0.08925771735435657: This value represents the average of the squares of the errors or deviations. The error is the amount by which the values predicted by the model differ from the actual values within the dataset. A lower MSE value indicates a better fit of the model to the data. In your case, the MSE is very low, suggesting that the model's predictions are very close to the actual values.\u001b[0m\n\u001b[1;37m                                                                                                                                                                                                                                                                                                                                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error (MSE) = 0.08925771735435657: This value represents the average of the squares of the errors or deviations. The error is the amount by which the values predicted by the model differ from the actual values within the dataset. A lower MSE value indicates a better fit of the model to the data. In your case, the MSE is very low, suggesting that the model's predictions are very close to the actual values.\n",
    "\n",
    "# R-squared (R²) = 0.9996523898513691: R² is a statistical measure that represents the proportion of the variance for the dependent variable that's explained by the independent variables in the model. It provides an indication of the goodness of fit of the model. R² values range from 0 to 1, where 1 indicates a perfect fit. An R² value of 0.99965 suggests that the model explains almost all of the variability of the response data around its mean, which is an excellent result.\n",
    "\n",
    "# In summary, these results imply that the model you've trained performs exceptionally well on the test data, with predictions that are very close to the actual values and an almost perfect explanation of the variance in the data. This level of performance is rare in real-world scenarios and may indicate a well-suited model for the problem at hand or a particularly well-behaved dataset. However, it's also worth considering the potential for overfitting, where the model may be too closely tailored to the training data, potentially impacting its generalization to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLYING BOOSTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/24/ec/ad387100fa3cc2b9b81af0829b5ecfe75ec5bb19dd7c19d4fea06fb81802/xgboost-2.0.3-py3-none-win_amd64.whl.metadata\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.26.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.12.0)\n",
      "Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/99.8 MB 330.3 kB/s eta 0:05:02\n",
      "   ---------------------------------------- 0.1/99.8 MB 469.7 kB/s eta 0:03:33\n",
      "   ---------------------------------------- 0.1/99.8 MB 950.9 kB/s eta 0:01:45\n",
      "    --------------------------------------- 1.4/99.8 MB 7.4 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 5.6/99.8 MB 25.4 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 10.3/99.8 MB 81.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 14.8/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 19.4/99.8 MB 131.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 24.1/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 28.4/99.8 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 32.0/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 36.4/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 40.8/99.8 MB 131.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 44.4/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 48.9/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 52.1/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 56.6/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 60.8/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 64.8/99.8 MB 131.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 69.3/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 72.9/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 77.3/99.8 MB 129.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 80.5/99.8 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 84.7/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 88.2/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 92.3/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.1/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.8/99.8 MB 8.7 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 8.891071193435837e-10\n",
      "R^2 Score: 0.9999999999965374\n"
     ]
    }
   ],
   "source": [
    "# Define the XGBoost regressor model\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100)\n",
    "\n",
    "# Create a pipeline that first preprocesses the data, then trains the model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', xgb_regressor)])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model is overfitting so i am goint to apply early stopping training will stop if the validation metric does not improve for 10 consecutive rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\2\\ipykernel_6060\\490613746.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  full_data['Working_Hours'] = (pd.to_datetime(full_data['Time_End']) - pd.to_datetime(full_data['Time_Start'])).dt.seconds / 3600\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\2\\ipykernel_6060\\490613746.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  full_data['Working_Hours'] = (pd.to_datetime(full_data['Time_End']) - pd.to_datetime(full_data['Time_Start'])).dt.seconds / 3600\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.read_csv(\"ourdata.csv\")\n",
    "\n",
    "# Feature engineering\n",
    "# Convert 'Date' to datetime and extract useful features\n",
    "full_data['Date'] = pd.to_datetime(full_data['Date'])\n",
    "full_data['Day_of_Week'] = full_data['Date'].dt.dayofweek\n",
    "full_data['Month'] = full_data['Date'].dt.month\n",
    "full_data['Working_Hours'] = (pd.to_datetime(full_data['Time_End']) - pd.to_datetime(full_data['Time_Start'])).dt.seconds / 3600\n",
    "\n",
    "# Select features and target\n",
    "X = full_data[['Day_of_Week', 'Month', 'Working_Hours', 'Base_Hourly_Wage', 'Supply_Demand_Ratio', 'Dynamic_Pricing_Multiplier']]\n",
    "y = full_data['Total_Earnings']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:15.89504\teval-rmse:15.56817\n",
      "[1]\ttrain-rmse:15.74558\teval-rmse:15.42139\n",
      "[2]\ttrain-rmse:15.59770\teval-rmse:15.27666\n",
      "[3]\ttrain-rmse:15.45126\teval-rmse:15.13307\n",
      "[4]\ttrain-rmse:15.30640\teval-rmse:14.99183\n",
      "[5]\ttrain-rmse:15.16291\teval-rmse:14.85114\n",
      "[6]\ttrain-rmse:15.02095\teval-rmse:14.71224\n",
      "[7]\ttrain-rmse:14.88031\teval-rmse:14.57468\n",
      "[8]\ttrain-rmse:14.74114\teval-rmse:14.43801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\ttrain-rmse:14.60331\teval-rmse:14.30358\n",
      "[10]\ttrain-rmse:14.46690\teval-rmse:14.16963\n",
      "[11]\ttrain-rmse:14.33180\teval-rmse:14.03788\n",
      "[12]\ttrain-rmse:14.19713\teval-rmse:13.90519\n",
      "[13]\ttrain-rmse:14.06457\teval-rmse:13.77593\n",
      "[14]\ttrain-rmse:13.93246\teval-rmse:13.64576\n",
      "[15]\ttrain-rmse:13.80171\teval-rmse:13.51768\n",
      "[16]\ttrain-rmse:13.67284\teval-rmse:13.39182\n",
      "[17]\ttrain-rmse:13.54456\teval-rmse:13.26600\n",
      "[18]\ttrain-rmse:13.41815\teval-rmse:13.14224\n",
      "[19]\ttrain-rmse:13.29231\teval-rmse:13.01880\n",
      "[20]\ttrain-rmse:13.16831\teval-rmse:12.89741\n",
      "[21]\ttrain-rmse:13.04486\teval-rmse:12.77632\n",
      "[22]\ttrain-rmse:12.92269\teval-rmse:12.65595\n",
      "[23]\ttrain-rmse:12.80212\teval-rmse:12.53791\n",
      "[24]\ttrain-rmse:12.68227\teval-rmse:12.42052\n",
      "[25]\ttrain-rmse:12.56402\teval-rmse:12.30476\n",
      "[26]\ttrain-rmse:12.44642\teval-rmse:12.18940\n",
      "[27]\ttrain-rmse:12.33005\teval-rmse:12.07527\n",
      "[28]\ttrain-rmse:12.21504\teval-rmse:11.96269\n",
      "[29]\ttrain-rmse:12.10088\teval-rmse:11.85072\n",
      "[30]\ttrain-rmse:11.98806\teval-rmse:11.74029\n",
      "[31]\ttrain-rmse:11.87607\teval-rmse:11.63044\n",
      "[32]\ttrain-rmse:11.76540\teval-rmse:11.52211\n",
      "[33]\ttrain-rmse:11.65553\teval-rmse:11.41435\n",
      "[34]\ttrain-rmse:11.54683\teval-rmse:11.30739\n",
      "[35]\ttrain-rmse:11.43923\teval-rmse:11.20207\n",
      "[36]\ttrain-rmse:11.33254\teval-rmse:11.09744\n",
      "[37]\ttrain-rmse:11.22699\teval-rmse:10.99412\n",
      "[38]\ttrain-rmse:11.12233\teval-rmse:10.89147\n",
      "[39]\ttrain-rmse:11.01877\teval-rmse:10.79012\n",
      "[40]\ttrain-rmse:10.91610\teval-rmse:10.68942\n",
      "[41]\ttrain-rmse:10.81450\teval-rmse:10.58934\n",
      "[42]\ttrain-rmse:10.71381\teval-rmse:10.49080\n",
      "[43]\ttrain-rmse:10.61411\teval-rmse:10.39303\n",
      "[44]\ttrain-rmse:10.51534\teval-rmse:10.29635\n",
      "[45]\ttrain-rmse:10.41753\teval-rmse:10.20043\n",
      "[46]\ttrain-rmse:10.32063\teval-rmse:10.10560\n",
      "[47]\ttrain-rmse:10.22468\teval-rmse:10.01150\n",
      "[48]\ttrain-rmse:10.12974\teval-rmse:9.91840\n",
      "[49]\ttrain-rmse:10.03549\teval-rmse:9.82616\n",
      "[50]\ttrain-rmse:9.94235\teval-rmse:9.73482\n",
      "[51]\ttrain-rmse:9.84988\teval-rmse:9.64433\n",
      "[52]\ttrain-rmse:9.75851\teval-rmse:9.55473\n",
      "[53]\ttrain-rmse:9.66809\teval-rmse:9.46554\n",
      "[54]\ttrain-rmse:9.57855\teval-rmse:9.37747\n",
      "[55]\ttrain-rmse:9.48965\teval-rmse:9.29107\n",
      "[56]\ttrain-rmse:9.40174\teval-rmse:9.20446\n",
      "[57]\ttrain-rmse:9.31458\teval-rmse:9.11901\n",
      "[58]\ttrain-rmse:9.22801\teval-rmse:9.03430\n",
      "[59]\ttrain-rmse:9.14263\teval-rmse:8.95058\n",
      "[60]\ttrain-rmse:9.05804\teval-rmse:8.86740\n",
      "[61]\ttrain-rmse:8.97415\teval-rmse:8.78539\n",
      "[62]\ttrain-rmse:8.89083\teval-rmse:8.70421\n",
      "[63]\ttrain-rmse:8.80868\teval-rmse:8.62327\n",
      "[64]\ttrain-rmse:8.72695\teval-rmse:8.54365\n",
      "[65]\ttrain-rmse:8.64636\teval-rmse:8.46407\n",
      "[66]\ttrain-rmse:8.56645\teval-rmse:8.38603\n",
      "[67]\ttrain-rmse:8.48694\teval-rmse:8.30824\n",
      "[68]\ttrain-rmse:8.40865\teval-rmse:8.23148\n",
      "[69]\ttrain-rmse:8.33106\teval-rmse:8.15538\n",
      "[70]\ttrain-rmse:8.25415\teval-rmse:8.08001\n",
      "[71]\ttrain-rmse:8.17760\teval-rmse:8.00512\n",
      "[72]\ttrain-rmse:8.10226\teval-rmse:7.93125\n",
      "[73]\ttrain-rmse:8.02719\teval-rmse:7.85813\n",
      "[74]\ttrain-rmse:7.95329\teval-rmse:7.78533\n",
      "[75]\ttrain-rmse:7.88017\teval-rmse:7.71369\n",
      "[76]\ttrain-rmse:7.80710\teval-rmse:7.64192\n",
      "[77]\ttrain-rmse:7.73533\teval-rmse:7.57151\n",
      "[78]\ttrain-rmse:7.66403\teval-rmse:7.50188\n",
      "[79]\ttrain-rmse:7.59363\teval-rmse:7.43278\n",
      "[80]\ttrain-rmse:7.52340\teval-rmse:7.36426\n",
      "[81]\ttrain-rmse:7.45420\teval-rmse:7.29675\n",
      "[82]\ttrain-rmse:7.38516\teval-rmse:7.22893\n",
      "[83]\ttrain-rmse:7.31738\teval-rmse:7.16269\n",
      "[84]\ttrain-rmse:7.25031\teval-rmse:7.09647\n",
      "[85]\ttrain-rmse:7.18343\teval-rmse:7.03100\n",
      "[86]\ttrain-rmse:7.11692\teval-rmse:6.96493\n",
      "[87]\ttrain-rmse:7.05170\teval-rmse:6.90113\n",
      "[88]\ttrain-rmse:6.98654\teval-rmse:6.83727\n",
      "[89]\ttrain-rmse:6.92245\teval-rmse:6.77466\n",
      "[90]\ttrain-rmse:6.85857\teval-rmse:6.71233\n",
      "[91]\ttrain-rmse:6.79565\teval-rmse:6.65083\n",
      "[92]\ttrain-rmse:6.73291\teval-rmse:6.58908\n",
      "[93]\ttrain-rmse:6.67121\teval-rmse:6.52869\n",
      "[94]\ttrain-rmse:6.61018\teval-rmse:6.46920\n",
      "[95]\ttrain-rmse:6.54920\teval-rmse:6.40942\n",
      "[96]\ttrain-rmse:6.48880\teval-rmse:6.34959\n",
      "[97]\ttrain-rmse:6.42948\teval-rmse:6.29152\n",
      "[98]\ttrain-rmse:6.37018\teval-rmse:6.23316\n",
      "[99]\ttrain-rmse:6.31188\teval-rmse:6.17617\n",
      "[100]\ttrain-rmse:6.25432\teval-rmse:6.11961\n",
      "[101]\ttrain-rmse:6.19671\teval-rmse:6.06340\n",
      "[102]\ttrain-rmse:6.13961\teval-rmse:6.00660\n",
      "[103]\ttrain-rmse:6.08356\teval-rmse:5.95145\n",
      "[104]\ttrain-rmse:6.02756\teval-rmse:5.89681\n",
      "[105]\ttrain-rmse:5.97245\teval-rmse:5.84273\n",
      "[106]\ttrain-rmse:5.91752\teval-rmse:5.78807\n",
      "[107]\ttrain-rmse:5.86341\teval-rmse:5.73536\n",
      "[108]\ttrain-rmse:5.80950\teval-rmse:5.68186\n",
      "[109]\ttrain-rmse:5.75644\teval-rmse:5.63050\n",
      "[110]\ttrain-rmse:5.70345\teval-rmse:5.57884\n",
      "[111]\ttrain-rmse:5.65093\teval-rmse:5.52646\n",
      "[112]\ttrain-rmse:5.59931\teval-rmse:5.47631\n",
      "[113]\ttrain-rmse:5.54783\teval-rmse:5.42586\n",
      "[114]\ttrain-rmse:5.49718\teval-rmse:5.37628\n",
      "[115]\ttrain-rmse:5.44712\teval-rmse:5.32764\n",
      "[116]\ttrain-rmse:5.39695\teval-rmse:5.27858\n",
      "[117]\ttrain-rmse:5.34752\teval-rmse:5.22968\n",
      "[118]\ttrain-rmse:5.29875\teval-rmse:5.18197\n",
      "[119]\ttrain-rmse:5.25002\teval-rmse:5.13456\n",
      "[120]\ttrain-rmse:5.20217\teval-rmse:5.08761\n",
      "[121]\ttrain-rmse:5.15475\teval-rmse:5.04137\n",
      "[122]\ttrain-rmse:5.10754\teval-rmse:4.99445\n",
      "[123]\ttrain-rmse:5.06060\teval-rmse:4.94878\n",
      "[124]\ttrain-rmse:5.01456\teval-rmse:4.90396\n",
      "[125]\ttrain-rmse:4.96863\teval-rmse:4.85839\n",
      "[126]\ttrain-rmse:4.92334\teval-rmse:4.81423\n",
      "[127]\ttrain-rmse:4.87850\teval-rmse:4.77067\n",
      "[128]\ttrain-rmse:4.83380\teval-rmse:4.72611\n",
      "[129]\ttrain-rmse:4.78945\teval-rmse:4.68296\n",
      "[130]\ttrain-rmse:4.74587\teval-rmse:4.64030\n",
      "[131]\ttrain-rmse:4.70279\teval-rmse:4.59846\n",
      "[132]\ttrain-rmse:4.65975\teval-rmse:4.55556\n",
      "[133]\ttrain-rmse:4.61711\teval-rmse:4.51420\n",
      "[134]\ttrain-rmse:4.57515\teval-rmse:4.47304\n",
      "[135]\ttrain-rmse:4.53343\teval-rmse:4.43179\n",
      "[136]\ttrain-rmse:4.49220\teval-rmse:4.39152\n",
      "[137]\ttrain-rmse:4.45148\teval-rmse:4.35199\n",
      "[138]\ttrain-rmse:4.41078\teval-rmse:4.31183\n",
      "[139]\ttrain-rmse:4.37048\teval-rmse:4.27275\n",
      "[140]\ttrain-rmse:4.33082\teval-rmse:4.23397\n",
      "[141]\ttrain-rmse:4.29153\teval-rmse:4.19550\n",
      "[142]\ttrain-rmse:4.25236\teval-rmse:4.15666\n",
      "[143]\ttrain-rmse:4.21382\teval-rmse:4.11941\n",
      "[144]\ttrain-rmse:4.17539\teval-rmse:4.08190\n",
      "[145]\ttrain-rmse:4.13723\teval-rmse:4.04394\n",
      "[146]\ttrain-rmse:4.09966\teval-rmse:4.00757\n",
      "[147]\ttrain-rmse:4.06252\teval-rmse:3.97130\n",
      "[148]\ttrain-rmse:4.02550\teval-rmse:3.93495\n",
      "[149]\ttrain-rmse:3.98908\teval-rmse:3.89983\n",
      "[150]\ttrain-rmse:3.95267\teval-rmse:3.86361\n",
      "[151]\ttrain-rmse:3.91669\teval-rmse:3.82850\n",
      "[152]\ttrain-rmse:3.88123\teval-rmse:3.79383\n",
      "[153]\ttrain-rmse:3.84610\teval-rmse:3.75967\n",
      "[154]\ttrain-rmse:3.81118\teval-rmse:3.72551\n",
      "[155]\ttrain-rmse:3.77674\teval-rmse:3.69180\n",
      "[156]\ttrain-rmse:3.74236\teval-rmse:3.65806\n",
      "[157]\ttrain-rmse:3.70848\teval-rmse:3.62496\n",
      "[158]\ttrain-rmse:3.67487\teval-rmse:3.59200\n",
      "[159]\ttrain-rmse:3.64162\teval-rmse:3.55953\n",
      "[160]\ttrain-rmse:3.60863\teval-rmse:3.52680\n",
      "[161]\ttrain-rmse:3.57597\teval-rmse:3.49511\n",
      "[162]\ttrain-rmse:3.54338\teval-rmse:3.46324\n",
      "[163]\ttrain-rmse:3.51150\teval-rmse:3.43215\n",
      "[164]\ttrain-rmse:3.47965\teval-rmse:3.40058\n",
      "[165]\ttrain-rmse:3.44811\teval-rmse:3.36968\n",
      "[166]\ttrain-rmse:3.41701\teval-rmse:3.33928\n",
      "[167]\ttrain-rmse:3.38604\teval-rmse:3.30888\n",
      "[168]\ttrain-rmse:3.35546\teval-rmse:3.27861\n",
      "[169]\ttrain-rmse:3.32524\teval-rmse:3.24911\n",
      "[170]\ttrain-rmse:3.29507\teval-rmse:3.21973\n",
      "[171]\ttrain-rmse:3.26537\teval-rmse:3.19074\n",
      "[172]\ttrain-rmse:3.23580\teval-rmse:3.16172\n",
      "[173]\ttrain-rmse:3.20660\teval-rmse:3.13320\n",
      "[174]\ttrain-rmse:3.17746\teval-rmse:3.10472\n",
      "[175]\ttrain-rmse:3.14885\teval-rmse:3.07701\n",
      "[176]\ttrain-rmse:3.12033\teval-rmse:3.04888\n",
      "[177]\ttrain-rmse:3.09222\teval-rmse:3.02170\n",
      "[178]\ttrain-rmse:3.06415\teval-rmse:2.99426\n",
      "[179]\ttrain-rmse:3.03666\teval-rmse:2.96751\n",
      "[180]\ttrain-rmse:3.00946\teval-rmse:2.94095\n",
      "[181]\ttrain-rmse:2.98223\teval-rmse:2.91409\n",
      "[182]\ttrain-rmse:2.95543\teval-rmse:2.88793\n",
      "[183]\ttrain-rmse:2.92860\teval-rmse:2.86171\n",
      "[184]\ttrain-rmse:2.90240\teval-rmse:2.83609\n",
      "[185]\ttrain-rmse:2.87609\teval-rmse:2.81038\n",
      "[186]\ttrain-rmse:2.85039\teval-rmse:2.78529\n",
      "[187]\ttrain-rmse:2.82459\teval-rmse:2.76004\n",
      "[188]\ttrain-rmse:2.79935\teval-rmse:2.73538\n",
      "[189]\ttrain-rmse:2.77399\teval-rmse:2.71058\n",
      "[190]\ttrain-rmse:2.74922\teval-rmse:2.68637\n",
      "[191]\ttrain-rmse:2.72435\teval-rmse:2.66206\n",
      "[192]\ttrain-rmse:2.70004\teval-rmse:2.63829\n",
      "[193]\ttrain-rmse:2.67567\teval-rmse:2.61427\n",
      "[194]\ttrain-rmse:2.65181\teval-rmse:2.59095\n",
      "[195]\ttrain-rmse:2.62782\teval-rmse:2.56749\n",
      "[196]\ttrain-rmse:2.60440\teval-rmse:2.54449\n",
      "[197]\ttrain-rmse:2.58123\teval-rmse:2.52185\n",
      "[198]\ttrain-rmse:2.55786\teval-rmse:2.49901\n",
      "[199]\ttrain-rmse:2.53511\teval-rmse:2.47662\n",
      "[200]\ttrain-rmse:2.51223\teval-rmse:2.45422\n",
      "[201]\ttrain-rmse:2.48992\teval-rmse:2.43237\n",
      "[202]\ttrain-rmse:2.46742\teval-rmse:2.41039\n",
      "[203]\ttrain-rmse:2.44551\teval-rmse:2.38894\n",
      "[204]\ttrain-rmse:2.42342\teval-rmse:2.36734\n",
      "[205]\ttrain-rmse:2.40193\teval-rmse:2.34624\n",
      "[206]\ttrain-rmse:2.38028\teval-rmse:2.32506\n",
      "[207]\ttrain-rmse:2.35919\teval-rmse:2.30436\n",
      "[208]\ttrain-rmse:2.33792\teval-rmse:2.28342\n",
      "[209]\ttrain-rmse:2.31712\teval-rmse:2.26304\n",
      "[210]\ttrain-rmse:2.29623\teval-rmse:2.24263\n",
      "[211]\ttrain-rmse:2.27590\teval-rmse:2.22270\n",
      "[212]\ttrain-rmse:2.25546\teval-rmse:2.20256\n",
      "[213]\ttrain-rmse:2.23550\teval-rmse:2.18297\n",
      "[214]\ttrain-rmse:2.21559\teval-rmse:2.16371\n",
      "[215]\ttrain-rmse:2.19563\teval-rmse:2.14421\n",
      "[216]\ttrain-rmse:2.17624\teval-rmse:2.12518\n",
      "[217]\ttrain-rmse:2.15667\teval-rmse:2.10606\n",
      "[218]\ttrain-rmse:2.13763\teval-rmse:2.08737\n",
      "[219]\ttrain-rmse:2.11846\teval-rmse:2.06849\n",
      "[220]\ttrain-rmse:2.09980\teval-rmse:2.05027\n",
      "[221]\ttrain-rmse:2.08091\teval-rmse:2.03181\n",
      "[222]\ttrain-rmse:2.06258\teval-rmse:2.01384\n",
      "[223]\ttrain-rmse:2.04405\teval-rmse:1.99574\n",
      "[224]\ttrain-rmse:2.02604\teval-rmse:1.97805\n",
      "[225]\ttrain-rmse:2.00790\teval-rmse:1.96032\n",
      "[226]\ttrain-rmse:1.99026\teval-rmse:1.94309\n",
      "[227]\ttrain-rmse:1.97240\teval-rmse:1.92564\n",
      "[228]\ttrain-rmse:1.95508\teval-rmse:1.90864\n",
      "[229]\ttrain-rmse:1.93755\teval-rmse:1.89151\n",
      "[230]\ttrain-rmse:1.92053\teval-rmse:1.87484\n",
      "[231]\ttrain-rmse:1.90333\teval-rmse:1.85804\n",
      "[232]\ttrain-rmse:1.88663\teval-rmse:1.84170\n",
      "[233]\ttrain-rmse:1.86976\teval-rmse:1.82510\n",
      "[234]\ttrain-rmse:1.85331\teval-rmse:1.80898\n",
      "[235]\ttrain-rmse:1.83677\teval-rmse:1.79281\n",
      "[236]\ttrain-rmse:1.82067\teval-rmse:1.77703\n",
      "[237]\ttrain-rmse:1.80442\teval-rmse:1.76105\n",
      "[238]\ttrain-rmse:1.78863\teval-rmse:1.74559\n",
      "[239]\ttrain-rmse:1.77295\teval-rmse:1.73014\n",
      "[240]\ttrain-rmse:1.75711\teval-rmse:1.71466\n",
      "[241]\ttrain-rmse:1.74147\teval-rmse:1.69937\n",
      "[242]\ttrain-rmse:1.72622\teval-rmse:1.68441\n",
      "[243]\ttrain-rmse:1.71109\teval-rmse:1.66956\n",
      "[244]\ttrain-rmse:1.69584\teval-rmse:1.65466\n",
      "[245]\ttrain-rmse:1.68076\teval-rmse:1.63984\n",
      "[246]\ttrain-rmse:1.66609\teval-rmse:1.62548\n",
      "[247]\ttrain-rmse:1.65155\teval-rmse:1.61124\n",
      "[248]\ttrain-rmse:1.63686\teval-rmse:1.59690\n",
      "[249]\ttrain-rmse:1.62261\teval-rmse:1.58295\n",
      "[250]\ttrain-rmse:1.60818\teval-rmse:1.56886\n",
      "[251]\ttrain-rmse:1.59418\teval-rmse:1.55516\n",
      "[252]\ttrain-rmse:1.58002\teval-rmse:1.54133\n",
      "[253]\ttrain-rmse:1.56627\teval-rmse:1.52787\n",
      "[254]\ttrain-rmse:1.55237\teval-rmse:1.51429\n",
      "[255]\ttrain-rmse:1.53890\teval-rmse:1.50115\n",
      "[256]\ttrain-rmse:1.52525\teval-rmse:1.48782\n",
      "[257]\ttrain-rmse:1.51200\teval-rmse:1.47485\n",
      "[258]\ttrain-rmse:1.49862\teval-rmse:1.46179\n",
      "[259]\ttrain-rmse:1.48562\teval-rmse:1.44902\n",
      "[260]\ttrain-rmse:1.47247\teval-rmse:1.43618\n",
      "[261]\ttrain-rmse:1.45972\teval-rmse:1.42376\n",
      "[262]\ttrain-rmse:1.44684\teval-rmse:1.41106\n",
      "[263]\ttrain-rmse:1.43409\teval-rmse:1.39860\n",
      "[264]\ttrain-rmse:1.42165\teval-rmse:1.38643\n",
      "[265]\ttrain-rmse:1.40928\teval-rmse:1.37416\n",
      "[266]\ttrain-rmse:1.39685\teval-rmse:1.36203\n",
      "[267]\ttrain-rmse:1.38476\teval-rmse:1.35019\n",
      "[268]\ttrain-rmse:1.37257\teval-rmse:1.33832\n",
      "[269]\ttrain-rmse:1.36070\teval-rmse:1.32671\n",
      "[270]\ttrain-rmse:1.34875\teval-rmse:1.31510\n",
      "[271]\ttrain-rmse:1.33709\teval-rmse:1.30361\n",
      "[272]\ttrain-rmse:1.32540\teval-rmse:1.29214\n",
      "[273]\ttrain-rmse:1.31378\teval-rmse:1.28087\n",
      "[274]\ttrain-rmse:1.30241\teval-rmse:1.26961\n",
      "[275]\ttrain-rmse:1.29116\teval-rmse:1.25848\n",
      "[276]\ttrain-rmse:1.27990\teval-rmse:1.24752\n",
      "[277]\ttrain-rmse:1.26888\teval-rmse:1.23666\n",
      "[278]\ttrain-rmse:1.25779\teval-rmse:1.22589\n",
      "[279]\ttrain-rmse:1.24694\teval-rmse:1.21515\n",
      "[280]\ttrain-rmse:1.23609\teval-rmse:1.20459\n",
      "[281]\ttrain-rmse:1.22545\teval-rmse:1.19406\n",
      "[282]\ttrain-rmse:1.21481\teval-rmse:1.18371\n",
      "[283]\ttrain-rmse:1.20436\teval-rmse:1.17340\n",
      "[284]\ttrain-rmse:1.19394\teval-rmse:1.16317\n",
      "[285]\ttrain-rmse:1.18359\teval-rmse:1.15309\n",
      "[286]\ttrain-rmse:1.17342\teval-rmse:1.14303\n",
      "[287]\ttrain-rmse:1.16322\teval-rmse:1.13313\n",
      "[288]\ttrain-rmse:1.15325\teval-rmse:1.12329\n",
      "[289]\ttrain-rmse:1.14328\teval-rmse:1.11359\n",
      "[290]\ttrain-rmse:1.13347\teval-rmse:1.10390\n",
      "[291]\ttrain-rmse:1.12370\teval-rmse:1.09431\n",
      "[292]\ttrain-rmse:1.11408\teval-rmse:1.08486\n",
      "[293]\ttrain-rmse:1.10442\teval-rmse:1.07548\n",
      "[294]\ttrain-rmse:1.09498\teval-rmse:1.06619\n",
      "[295]\ttrain-rmse:1.08554\teval-rmse:1.05701\n",
      "[296]\ttrain-rmse:1.07628\teval-rmse:1.04789\n",
      "[297]\ttrain-rmse:1.06698\teval-rmse:1.03878\n",
      "[298]\ttrain-rmse:1.05781\teval-rmse:1.02986\n",
      "[299]\ttrain-rmse:1.04878\teval-rmse:1.02092\n",
      "[300]\ttrain-rmse:1.03977\teval-rmse:1.01216\n",
      "[301]\ttrain-rmse:1.03093\teval-rmse:1.00345\n",
      "[302]\ttrain-rmse:1.02211\teval-rmse:0.99480\n",
      "[303]\ttrain-rmse:1.01341\teval-rmse:0.98619\n",
      "[304]\ttrain-rmse:1.00473\teval-rmse:0.97775\n",
      "[305]\ttrain-rmse:0.99620\teval-rmse:0.96930\n",
      "[306]\ttrain-rmse:0.98768\teval-rmse:0.96101\n",
      "[307]\ttrain-rmse:0.97930\teval-rmse:0.95279\n",
      "[308]\ttrain-rmse:0.97090\teval-rmse:0.94457\n",
      "[309]\ttrain-rmse:0.96268\teval-rmse:0.93650\n",
      "[310]\ttrain-rmse:0.95443\teval-rmse:0.92843\n",
      "[311]\ttrain-rmse:0.94628\teval-rmse:0.92045\n",
      "[312]\ttrain-rmse:0.93823\teval-rmse:0.91266\n",
      "[313]\ttrain-rmse:0.93021\teval-rmse:0.90483\n",
      "[314]\ttrain-rmse:0.92231\teval-rmse:0.89718\n",
      "[315]\ttrain-rmse:0.91451\teval-rmse:0.88953\n",
      "[316]\ttrain-rmse:0.90671\teval-rmse:0.88192\n",
      "[317]\ttrain-rmse:0.89902\teval-rmse:0.87448\n",
      "[318]\ttrain-rmse:0.89140\teval-rmse:0.86707\n",
      "[319]\ttrain-rmse:0.88389\teval-rmse:0.85970\n",
      "[320]\ttrain-rmse:0.87637\teval-rmse:0.85237\n",
      "[321]\ttrain-rmse:0.86896\teval-rmse:0.84519\n",
      "[322]\ttrain-rmse:0.86160\teval-rmse:0.83802\n",
      "[323]\ttrain-rmse:0.85433\teval-rmse:0.83098\n",
      "[324]\ttrain-rmse:0.84709\teval-rmse:0.82391\n",
      "[325]\ttrain-rmse:0.83994\teval-rmse:0.81701\n",
      "[326]\ttrain-rmse:0.83285\teval-rmse:0.81006\n",
      "[327]\ttrain-rmse:0.82584\teval-rmse:0.80327\n",
      "[328]\ttrain-rmse:0.81887\teval-rmse:0.79646\n",
      "[329]\ttrain-rmse:0.81191\teval-rmse:0.78971\n",
      "[330]\ttrain-rmse:0.80509\teval-rmse:0.78302\n",
      "[331]\ttrain-rmse:0.79832\teval-rmse:0.77644\n",
      "[332]\ttrain-rmse:0.79159\teval-rmse:0.76990\n",
      "[333]\ttrain-rmse:0.78488\teval-rmse:0.76341\n",
      "[334]\ttrain-rmse:0.77830\teval-rmse:0.75696\n",
      "[335]\ttrain-rmse:0.77179\teval-rmse:0.75059\n",
      "[336]\ttrain-rmse:0.76531\teval-rmse:0.74425\n",
      "[337]\ttrain-rmse:0.75889\teval-rmse:0.73798\n",
      "[338]\ttrain-rmse:0.75258\teval-rmse:0.73185\n",
      "[339]\ttrain-rmse:0.74627\teval-rmse:0.72569\n",
      "[340]\ttrain-rmse:0.74004\teval-rmse:0.71966\n",
      "[341]\ttrain-rmse:0.73391\teval-rmse:0.71371\n",
      "[342]\ttrain-rmse:0.72777\teval-rmse:0.70771\n",
      "[343]\ttrain-rmse:0.72176\teval-rmse:0.70180\n",
      "[344]\ttrain-rmse:0.71572\teval-rmse:0.69591\n",
      "[345]\ttrain-rmse:0.70976\teval-rmse:0.69015\n",
      "[346]\ttrain-rmse:0.70391\teval-rmse:0.68439\n",
      "[347]\ttrain-rmse:0.69811\teval-rmse:0.67876\n",
      "[348]\ttrain-rmse:0.69229\teval-rmse:0.67312\n",
      "[349]\ttrain-rmse:0.68659\teval-rmse:0.66748\n",
      "[350]\ttrain-rmse:0.68096\teval-rmse:0.66186\n",
      "[351]\ttrain-rmse:0.67536\teval-rmse:0.65643\n",
      "[352]\ttrain-rmse:0.66976\teval-rmse:0.65099\n",
      "[353]\ttrain-rmse:0.66429\teval-rmse:0.64555\n",
      "[354]\ttrain-rmse:0.65880\teval-rmse:0.64024\n",
      "[355]\ttrain-rmse:0.65340\teval-rmse:0.63494\n",
      "[356]\ttrain-rmse:0.64805\teval-rmse:0.62961\n",
      "[357]\ttrain-rmse:0.64271\teval-rmse:0.62445\n",
      "[358]\ttrain-rmse:0.63747\teval-rmse:0.61922\n",
      "[359]\ttrain-rmse:0.63226\teval-rmse:0.61417\n",
      "[360]\ttrain-rmse:0.62705\teval-rmse:0.60904\n",
      "[361]\ttrain-rmse:0.62195\teval-rmse:0.60395\n",
      "[362]\ttrain-rmse:0.61684\teval-rmse:0.59904\n",
      "[363]\ttrain-rmse:0.61177\teval-rmse:0.59410\n",
      "[364]\ttrain-rmse:0.60681\teval-rmse:0.58917\n",
      "[365]\ttrain-rmse:0.60184\teval-rmse:0.58437\n",
      "[366]\ttrain-rmse:0.59697\teval-rmse:0.57948\n",
      "[367]\ttrain-rmse:0.59213\teval-rmse:0.57480\n",
      "[368]\ttrain-rmse:0.58732\teval-rmse:0.57002\n",
      "[369]\ttrain-rmse:0.58257\teval-rmse:0.56541\n",
      "[370]\ttrain-rmse:0.57782\teval-rmse:0.56076\n",
      "[371]\ttrain-rmse:0.57315\teval-rmse:0.55610\n",
      "[372]\ttrain-rmse:0.56851\teval-rmse:0.55162\n",
      "[373]\ttrain-rmse:0.56391\teval-rmse:0.54704\n",
      "[374]\ttrain-rmse:0.55936\teval-rmse:0.54264\n",
      "[375]\ttrain-rmse:0.55480\teval-rmse:0.53821\n",
      "[376]\ttrain-rmse:0.55035\teval-rmse:0.53379\n",
      "[377]\ttrain-rmse:0.54589\teval-rmse:0.52950\n",
      "[378]\ttrain-rmse:0.54151\teval-rmse:0.52512\n",
      "[379]\ttrain-rmse:0.53716\teval-rmse:0.52092\n",
      "[380]\ttrain-rmse:0.53285\teval-rmse:0.51665\n",
      "[381]\ttrain-rmse:0.52855\teval-rmse:0.51245\n",
      "[382]\ttrain-rmse:0.52434\teval-rmse:0.50822\n",
      "[383]\ttrain-rmse:0.52015\teval-rmse:0.50418\n",
      "[384]\ttrain-rmse:0.51601\teval-rmse:0.50004\n",
      "[385]\ttrain-rmse:0.51187\teval-rmse:0.49606\n",
      "[386]\ttrain-rmse:0.50780\teval-rmse:0.49200\n",
      "[387]\ttrain-rmse:0.50373\teval-rmse:0.48809\n",
      "[388]\ttrain-rmse:0.49975\teval-rmse:0.48414\n",
      "[389]\ttrain-rmse:0.49576\teval-rmse:0.48030\n",
      "[390]\ttrain-rmse:0.49182\teval-rmse:0.47638\n",
      "[391]\ttrain-rmse:0.48793\teval-rmse:0.47263\n",
      "[392]\ttrain-rmse:0.48401\teval-rmse:0.46876\n",
      "[393]\ttrain-rmse:0.48021\teval-rmse:0.46497\n",
      "[394]\ttrain-rmse:0.47639\teval-rmse:0.46130\n",
      "[395]\ttrain-rmse:0.47265\teval-rmse:0.45758\n",
      "[396]\ttrain-rmse:0.46890\teval-rmse:0.45397\n",
      "[397]\ttrain-rmse:0.46520\teval-rmse:0.45042\n",
      "[398]\ttrain-rmse:0.46150\teval-rmse:0.44687\n",
      "[399]\ttrain-rmse:0.45785\teval-rmse:0.44336\n",
      "[400]\ttrain-rmse:0.45428\teval-rmse:0.43981\n",
      "[401]\ttrain-rmse:0.45070\teval-rmse:0.43637\n",
      "[402]\ttrain-rmse:0.44714\teval-rmse:0.43296\n",
      "[403]\ttrain-rmse:0.44366\teval-rmse:0.42947\n",
      "[404]\ttrain-rmse:0.44016\teval-rmse:0.42608\n",
      "[405]\ttrain-rmse:0.43667\teval-rmse:0.42272\n",
      "[406]\ttrain-rmse:0.43323\teval-rmse:0.41933\n",
      "[407]\ttrain-rmse:0.42984\teval-rmse:0.41609\n",
      "[408]\ttrain-rmse:0.42647\teval-rmse:0.41286\n",
      "[409]\ttrain-rmse:0.42317\teval-rmse:0.40964\n",
      "[410]\ttrain-rmse:0.41988\teval-rmse:0.40650\n",
      "[411]\ttrain-rmse:0.41656\teval-rmse:0.40331\n",
      "[412]\ttrain-rmse:0.41333\teval-rmse:0.40019\n",
      "[413]\ttrain-rmse:0.41017\teval-rmse:0.39710\n",
      "[414]\ttrain-rmse:0.40702\teval-rmse:0.39395\n",
      "[415]\ttrain-rmse:0.40386\teval-rmse:0.39087\n",
      "[416]\ttrain-rmse:0.40074\teval-rmse:0.38789\n",
      "[417]\ttrain-rmse:0.39766\teval-rmse:0.38487\n",
      "[418]\ttrain-rmse:0.39458\teval-rmse:0.38191\n",
      "[419]\ttrain-rmse:0.39153\teval-rmse:0.37899\n",
      "[420]\ttrain-rmse:0.38849\teval-rmse:0.37595\n",
      "[421]\ttrain-rmse:0.38549\teval-rmse:0.37295\n",
      "[422]\ttrain-rmse:0.38251\teval-rmse:0.37009\n",
      "[423]\ttrain-rmse:0.37954\teval-rmse:0.36713\n",
      "[424]\ttrain-rmse:0.37661\teval-rmse:0.36420\n",
      "[425]\ttrain-rmse:0.37371\teval-rmse:0.36130\n",
      "[426]\ttrain-rmse:0.37080\teval-rmse:0.35851\n",
      "[427]\ttrain-rmse:0.36790\teval-rmse:0.35568\n",
      "[428]\ttrain-rmse:0.36509\teval-rmse:0.35288\n",
      "[429]\ttrain-rmse:0.36227\teval-rmse:0.35016\n",
      "[430]\ttrain-rmse:0.35953\teval-rmse:0.34750\n",
      "[431]\ttrain-rmse:0.35679\teval-rmse:0.34477\n",
      "[432]\ttrain-rmse:0.35409\teval-rmse:0.34207\n",
      "[433]\ttrain-rmse:0.35134\teval-rmse:0.33939\n",
      "[434]\ttrain-rmse:0.34869\teval-rmse:0.33675\n",
      "[435]\ttrain-rmse:0.34603\teval-rmse:0.33421\n",
      "[436]\ttrain-rmse:0.34341\teval-rmse:0.33160\n",
      "[437]\ttrain-rmse:0.34077\teval-rmse:0.32906\n",
      "[438]\ttrain-rmse:0.33823\teval-rmse:0.32659\n",
      "[439]\ttrain-rmse:0.33567\teval-rmse:0.32405\n",
      "[440]\ttrain-rmse:0.33315\teval-rmse:0.32165\n",
      "[441]\ttrain-rmse:0.33065\teval-rmse:0.31915\n",
      "[442]\ttrain-rmse:0.32814\teval-rmse:0.31677\n",
      "[443]\ttrain-rmse:0.32569\teval-rmse:0.31432\n",
      "[444]\ttrain-rmse:0.32327\teval-rmse:0.31191\n",
      "[445]\ttrain-rmse:0.32089\teval-rmse:0.30961\n",
      "[446]\ttrain-rmse:0.31844\teval-rmse:0.30728\n",
      "[447]\ttrain-rmse:0.31607\teval-rmse:0.30496\n",
      "[448]\ttrain-rmse:0.31372\teval-rmse:0.30273\n",
      "[449]\ttrain-rmse:0.31135\teval-rmse:0.30047\n",
      "[450]\ttrain-rmse:0.30901\teval-rmse:0.29824\n",
      "[451]\ttrain-rmse:0.30673\teval-rmse:0.29598\n",
      "[452]\ttrain-rmse:0.30442\teval-rmse:0.29378\n",
      "[453]\ttrain-rmse:0.30222\teval-rmse:0.29163\n",
      "[454]\ttrain-rmse:0.30000\teval-rmse:0.28943\n",
      "[455]\ttrain-rmse:0.29784\teval-rmse:0.28731\n",
      "[456]\ttrain-rmse:0.29562\teval-rmse:0.28520\n",
      "[457]\ttrain-rmse:0.29342\teval-rmse:0.28306\n",
      "[458]\ttrain-rmse:0.29124\teval-rmse:0.28099\n",
      "[459]\ttrain-rmse:0.28908\teval-rmse:0.27894\n",
      "[460]\ttrain-rmse:0.28700\teval-rmse:0.27691\n",
      "[461]\ttrain-rmse:0.28488\teval-rmse:0.27489\n",
      "[462]\ttrain-rmse:0.28279\teval-rmse:0.27286\n",
      "[463]\ttrain-rmse:0.28074\teval-rmse:0.27083\n",
      "[464]\ttrain-rmse:0.27868\teval-rmse:0.26886\n",
      "[465]\ttrain-rmse:0.27666\teval-rmse:0.26692\n",
      "[466]\ttrain-rmse:0.27467\teval-rmse:0.26494\n",
      "[467]\ttrain-rmse:0.27271\teval-rmse:0.26303\n",
      "[468]\ttrain-rmse:0.27073\teval-rmse:0.26115\n",
      "[469]\ttrain-rmse:0.26882\teval-rmse:0.25934\n",
      "[470]\ttrain-rmse:0.26691\teval-rmse:0.25743\n",
      "[471]\ttrain-rmse:0.26496\teval-rmse:0.25558\n",
      "[472]\ttrain-rmse:0.26306\teval-rmse:0.25377\n",
      "[473]\ttrain-rmse:0.26120\teval-rmse:0.25195\n",
      "[474]\ttrain-rmse:0.25932\teval-rmse:0.25016\n",
      "[475]\ttrain-rmse:0.25747\teval-rmse:0.24838\n",
      "[476]\ttrain-rmse:0.25565\teval-rmse:0.24656\n",
      "[477]\ttrain-rmse:0.25383\teval-rmse:0.24482\n",
      "[478]\ttrain-rmse:0.25205\teval-rmse:0.24308\n",
      "[479]\ttrain-rmse:0.25027\teval-rmse:0.24140\n",
      "[480]\ttrain-rmse:0.24848\teval-rmse:0.23969\n",
      "[481]\ttrain-rmse:0.24674\teval-rmse:0.23799\n",
      "[482]\ttrain-rmse:0.24503\teval-rmse:0.23628\n",
      "[483]\ttrain-rmse:0.24331\teval-rmse:0.23462\n",
      "[484]\ttrain-rmse:0.24161\teval-rmse:0.23292\n",
      "[485]\ttrain-rmse:0.23994\teval-rmse:0.23136\n",
      "[486]\ttrain-rmse:0.23825\teval-rmse:0.22977\n",
      "[487]\ttrain-rmse:0.23661\teval-rmse:0.22813\n",
      "[488]\ttrain-rmse:0.23497\teval-rmse:0.22658\n",
      "[489]\ttrain-rmse:0.23334\teval-rmse:0.22501\n",
      "[490]\ttrain-rmse:0.23172\teval-rmse:0.22340\n",
      "[491]\ttrain-rmse:0.23014\teval-rmse:0.22187\n",
      "[492]\ttrain-rmse:0.22855\teval-rmse:0.22036\n",
      "[493]\ttrain-rmse:0.22695\teval-rmse:0.21883\n",
      "[494]\ttrain-rmse:0.22539\teval-rmse:0.21728\n",
      "[495]\ttrain-rmse:0.22386\teval-rmse:0.21586\n",
      "[496]\ttrain-rmse:0.22233\teval-rmse:0.21436\n",
      "[497]\ttrain-rmse:0.22081\teval-rmse:0.21285\n",
      "[498]\ttrain-rmse:0.21930\teval-rmse:0.21139\n",
      "[499]\ttrain-rmse:0.21779\teval-rmse:0.20996\n",
      "[500]\ttrain-rmse:0.21632\teval-rmse:0.20857\n",
      "[501]\ttrain-rmse:0.21485\teval-rmse:0.20711\n",
      "[502]\ttrain-rmse:0.21341\teval-rmse:0.20577\n",
      "[503]\ttrain-rmse:0.21196\teval-rmse:0.20438\n",
      "[504]\ttrain-rmse:0.21053\teval-rmse:0.20298\n",
      "[505]\ttrain-rmse:0.20911\teval-rmse:0.20156\n",
      "[506]\ttrain-rmse:0.20772\teval-rmse:0.20022\n",
      "[507]\ttrain-rmse:0.20633\teval-rmse:0.19888\n",
      "[508]\ttrain-rmse:0.20495\teval-rmse:0.19750\n",
      "[509]\ttrain-rmse:0.20359\teval-rmse:0.19622\n",
      "[510]\ttrain-rmse:0.20223\teval-rmse:0.19487\n",
      "[511]\ttrain-rmse:0.20091\teval-rmse:0.19363\n",
      "[512]\ttrain-rmse:0.19957\teval-rmse:0.19235\n",
      "[513]\ttrain-rmse:0.19825\teval-rmse:0.19103\n",
      "[514]\ttrain-rmse:0.19696\teval-rmse:0.18978\n",
      "[515]\ttrain-rmse:0.19565\teval-rmse:0.18854\n",
      "[516]\ttrain-rmse:0.19437\teval-rmse:0.18733\n",
      "[517]\ttrain-rmse:0.19309\teval-rmse:0.18610\n",
      "[518]\ttrain-rmse:0.19182\teval-rmse:0.18483\n",
      "[519]\ttrain-rmse:0.19058\teval-rmse:0.18364\n",
      "[520]\ttrain-rmse:0.18932\teval-rmse:0.18245\n",
      "[521]\ttrain-rmse:0.18809\teval-rmse:0.18126\n",
      "[522]\ttrain-rmse:0.18687\teval-rmse:0.18004\n",
      "[523]\ttrain-rmse:0.18567\teval-rmse:0.17888\n",
      "[524]\ttrain-rmse:0.18447\teval-rmse:0.17768\n",
      "[525]\ttrain-rmse:0.18330\teval-rmse:0.17659\n",
      "[526]\ttrain-rmse:0.18210\teval-rmse:0.17546\n",
      "[527]\ttrain-rmse:0.18094\teval-rmse:0.17434\n",
      "[528]\ttrain-rmse:0.17978\teval-rmse:0.17317\n",
      "[529]\ttrain-rmse:0.17863\teval-rmse:0.17209\n",
      "[530]\ttrain-rmse:0.17749\teval-rmse:0.17099\n",
      "[531]\ttrain-rmse:0.17635\teval-rmse:0.16986\n",
      "[532]\ttrain-rmse:0.17523\teval-rmse:0.16874\n",
      "[533]\ttrain-rmse:0.17413\teval-rmse:0.16772\n",
      "[534]\ttrain-rmse:0.17303\teval-rmse:0.16664\n",
      "[535]\ttrain-rmse:0.17192\teval-rmse:0.16559\n",
      "[536]\ttrain-rmse:0.17085\teval-rmse:0.16455\n",
      "[537]\ttrain-rmse:0.16977\teval-rmse:0.16347\n",
      "[538]\ttrain-rmse:0.16871\teval-rmse:0.16245\n",
      "[539]\ttrain-rmse:0.16767\teval-rmse:0.16144\n",
      "[540]\ttrain-rmse:0.16662\teval-rmse:0.16039\n",
      "[541]\ttrain-rmse:0.16556\teval-rmse:0.15940\n",
      "[542]\ttrain-rmse:0.16457\teval-rmse:0.15845\n",
      "[543]\ttrain-rmse:0.16355\teval-rmse:0.15748\n",
      "[544]\ttrain-rmse:0.16253\teval-rmse:0.15646\n",
      "[545]\ttrain-rmse:0.16152\teval-rmse:0.15545\n",
      "[546]\ttrain-rmse:0.16056\teval-rmse:0.15454\n",
      "[547]\ttrain-rmse:0.15956\teval-rmse:0.15357\n",
      "[548]\ttrain-rmse:0.15857\teval-rmse:0.15259\n",
      "[549]\ttrain-rmse:0.15759\teval-rmse:0.15166\n",
      "[550]\ttrain-rmse:0.15665\teval-rmse:0.15077\n",
      "[551]\ttrain-rmse:0.15570\teval-rmse:0.14982\n",
      "[552]\ttrain-rmse:0.15477\teval-rmse:0.14893\n",
      "[553]\ttrain-rmse:0.15383\teval-rmse:0.14799\n",
      "[554]\ttrain-rmse:0.15291\teval-rmse:0.14714\n",
      "[555]\ttrain-rmse:0.15198\teval-rmse:0.14624\n",
      "[556]\ttrain-rmse:0.15107\teval-rmse:0.14533\n",
      "[557]\ttrain-rmse:0.15020\teval-rmse:0.14447\n",
      "[558]\ttrain-rmse:0.14928\teval-rmse:0.14361\n",
      "[559]\ttrain-rmse:0.14839\teval-rmse:0.14272\n",
      "[560]\ttrain-rmse:0.14753\teval-rmse:0.14189\n",
      "[561]\ttrain-rmse:0.14666\teval-rmse:0.14108\n",
      "[562]\ttrain-rmse:0.14579\teval-rmse:0.14021\n",
      "[563]\ttrain-rmse:0.14495\teval-rmse:0.13941\n",
      "[564]\ttrain-rmse:0.14406\teval-rmse:0.13852\n",
      "[565]\ttrain-rmse:0.14322\teval-rmse:0.13774\n",
      "[566]\ttrain-rmse:0.14236\teval-rmse:0.13687\n",
      "[567]\ttrain-rmse:0.14156\teval-rmse:0.13613\n",
      "[568]\ttrain-rmse:0.14071\teval-rmse:0.13527\n",
      "[569]\ttrain-rmse:0.13991\teval-rmse:0.13451\n",
      "[570]\ttrain-rmse:0.13908\teval-rmse:0.13374\n",
      "[571]\ttrain-rmse:0.13831\teval-rmse:0.13298\n",
      "[572]\ttrain-rmse:0.13749\teval-rmse:0.13215\n",
      "[573]\ttrain-rmse:0.13671\teval-rmse:0.13141\n",
      "[574]\ttrain-rmse:0.13590\teval-rmse:0.13060\n",
      "[575]\ttrain-rmse:0.13516\teval-rmse:0.12990\n",
      "[576]\ttrain-rmse:0.13438\teval-rmse:0.12916\n",
      "[577]\ttrain-rmse:0.13361\teval-rmse:0.12841\n",
      "[578]\ttrain-rmse:0.13284\teval-rmse:0.12765\n",
      "[579]\ttrain-rmse:0.13210\teval-rmse:0.12695\n",
      "[580]\ttrain-rmse:0.13133\teval-rmse:0.12618\n",
      "[581]\ttrain-rmse:0.13058\teval-rmse:0.12544\n",
      "[582]\ttrain-rmse:0.12983\teval-rmse:0.12474\n",
      "[583]\ttrain-rmse:0.12912\teval-rmse:0.12406\n",
      "[584]\ttrain-rmse:0.12840\teval-rmse:0.12335\n",
      "[585]\ttrain-rmse:0.12767\teval-rmse:0.12264\n",
      "[586]\ttrain-rmse:0.12693\teval-rmse:0.12191\n",
      "[587]\ttrain-rmse:0.12622\teval-rmse:0.12121\n",
      "[588]\ttrain-rmse:0.12551\teval-rmse:0.12054\n",
      "[589]\ttrain-rmse:0.12483\teval-rmse:0.11990\n",
      "[590]\ttrain-rmse:0.12415\teval-rmse:0.11922\n",
      "[591]\ttrain-rmse:0.12343\teval-rmse:0.11852\n",
      "[592]\ttrain-rmse:0.12272\teval-rmse:0.11785\n",
      "[593]\ttrain-rmse:0.12203\teval-rmse:0.11716\n",
      "[594]\ttrain-rmse:0.12138\teval-rmse:0.11650\n",
      "[595]\ttrain-rmse:0.12074\teval-rmse:0.11589\n",
      "[596]\ttrain-rmse:0.12007\teval-rmse:0.11527\n",
      "[597]\ttrain-rmse:0.11943\teval-rmse:0.11463\n",
      "[598]\ttrain-rmse:0.11880\teval-rmse:0.11405\n",
      "[599]\ttrain-rmse:0.11814\teval-rmse:0.11339\n",
      "[600]\ttrain-rmse:0.11754\teval-rmse:0.11281\n",
      "[601]\ttrain-rmse:0.11691\teval-rmse:0.11218\n",
      "[602]\ttrain-rmse:0.11631\teval-rmse:0.11162\n",
      "[603]\ttrain-rmse:0.11566\teval-rmse:0.11101\n",
      "[604]\ttrain-rmse:0.11504\teval-rmse:0.11040\n",
      "[605]\ttrain-rmse:0.11446\teval-rmse:0.10986\n",
      "[606]\ttrain-rmse:0.11386\teval-rmse:0.10926\n",
      "[607]\ttrain-rmse:0.11323\teval-rmse:0.10864\n",
      "[608]\ttrain-rmse:0.11265\teval-rmse:0.10810\n",
      "[609]\ttrain-rmse:0.11204\teval-rmse:0.10750\n",
      "[610]\ttrain-rmse:0.11149\teval-rmse:0.10698\n",
      "[611]\ttrain-rmse:0.11090\teval-rmse:0.10643\n",
      "[612]\ttrain-rmse:0.11035\teval-rmse:0.10587\n",
      "[613]\ttrain-rmse:0.10973\teval-rmse:0.10528\n",
      "[614]\ttrain-rmse:0.10917\teval-rmse:0.10471\n",
      "[615]\ttrain-rmse:0.10854\teval-rmse:0.10411\n",
      "[616]\ttrain-rmse:0.10798\teval-rmse:0.10357\n",
      "[617]\ttrain-rmse:0.10742\teval-rmse:0.10305\n",
      "[618]\ttrain-rmse:0.10690\teval-rmse:0.10256\n",
      "[619]\ttrain-rmse:0.10634\teval-rmse:0.10201\n",
      "[620]\ttrain-rmse:0.10574\teval-rmse:0.10142\n",
      "[621]\ttrain-rmse:0.10524\teval-rmse:0.10092\n",
      "[622]\ttrain-rmse:0.10465\teval-rmse:0.10035\n",
      "[623]\ttrain-rmse:0.10415\teval-rmse:0.09986\n",
      "[624]\ttrain-rmse:0.10361\teval-rmse:0.09933\n",
      "[625]\ttrain-rmse:0.10305\teval-rmse:0.09880\n",
      "[626]\ttrain-rmse:0.10255\teval-rmse:0.09830\n",
      "[627]\ttrain-rmse:0.10202\teval-rmse:0.09778\n",
      "[628]\ttrain-rmse:0.10152\teval-rmse:0.09729\n",
      "[629]\ttrain-rmse:0.10099\teval-rmse:0.09678\n",
      "[630]\ttrain-rmse:0.10050\teval-rmse:0.09630\n",
      "[631]\ttrain-rmse:0.09999\teval-rmse:0.09580\n",
      "[632]\ttrain-rmse:0.09945\teval-rmse:0.09528\n",
      "[633]\ttrain-rmse:0.09899\teval-rmse:0.09482\n",
      "[634]\ttrain-rmse:0.09849\teval-rmse:0.09434\n",
      "[635]\ttrain-rmse:0.09805\teval-rmse:0.09390\n",
      "[636]\ttrain-rmse:0.09753\teval-rmse:0.09339\n",
      "[637]\ttrain-rmse:0.09705\teval-rmse:0.09295\n",
      "[638]\ttrain-rmse:0.09656\teval-rmse:0.09248\n",
      "[639]\ttrain-rmse:0.09611\teval-rmse:0.09203\n",
      "[640]\ttrain-rmse:0.09563\teval-rmse:0.09157\n",
      "[641]\ttrain-rmse:0.09519\teval-rmse:0.09114\n",
      "[642]\ttrain-rmse:0.09471\teval-rmse:0.09068\n",
      "[643]\ttrain-rmse:0.09428\teval-rmse:0.09026\n",
      "[644]\ttrain-rmse:0.09382\teval-rmse:0.08981\n",
      "[645]\ttrain-rmse:0.09336\teval-rmse:0.08936\n",
      "[646]\ttrain-rmse:0.09295\teval-rmse:0.08896\n",
      "[647]\ttrain-rmse:0.09248\teval-rmse:0.08850\n",
      "[648]\ttrain-rmse:0.09206\teval-rmse:0.08809\n",
      "[649]\ttrain-rmse:0.09163\teval-rmse:0.08767\n",
      "[650]\ttrain-rmse:0.09118\teval-rmse:0.08725\n",
      "[651]\ttrain-rmse:0.09080\teval-rmse:0.08686\n",
      "[652]\ttrain-rmse:0.09034\teval-rmse:0.08642\n",
      "[653]\ttrain-rmse:0.08994\teval-rmse:0.08602\n",
      "[654]\ttrain-rmse:0.08951\teval-rmse:0.08561\n",
      "[655]\ttrain-rmse:0.08912\teval-rmse:0.08522\n",
      "[656]\ttrain-rmse:0.08870\teval-rmse:0.08482\n",
      "[657]\ttrain-rmse:0.08830\teval-rmse:0.08445\n",
      "[658]\ttrain-rmse:0.08788\teval-rmse:0.08404\n",
      "[659]\ttrain-rmse:0.08750\teval-rmse:0.08367\n",
      "[660]\ttrain-rmse:0.08710\teval-rmse:0.08328\n",
      "[661]\ttrain-rmse:0.08673\teval-rmse:0.08291\n",
      "[662]\ttrain-rmse:0.08632\teval-rmse:0.08252\n",
      "[663]\ttrain-rmse:0.08593\teval-rmse:0.08214\n",
      "[664]\ttrain-rmse:0.08557\teval-rmse:0.08178\n",
      "[665]\ttrain-rmse:0.08517\teval-rmse:0.08141\n",
      "[666]\ttrain-rmse:0.08482\teval-rmse:0.08106\n",
      "[667]\ttrain-rmse:0.08444\teval-rmse:0.08069\n",
      "[668]\ttrain-rmse:0.08409\teval-rmse:0.08035\n",
      "[669]\ttrain-rmse:0.08371\teval-rmse:0.07998\n",
      "[670]\ttrain-rmse:0.08329\teval-rmse:0.07960\n",
      "[671]\ttrain-rmse:0.08293\teval-rmse:0.07924\n",
      "[672]\ttrain-rmse:0.08259\teval-rmse:0.07891\n",
      "[673]\ttrain-rmse:0.08223\teval-rmse:0.07855\n",
      "[674]\ttrain-rmse:0.08183\teval-rmse:0.07818\n",
      "[675]\ttrain-rmse:0.08150\teval-rmse:0.07786\n",
      "[676]\ttrain-rmse:0.08114\teval-rmse:0.07752\n",
      "[677]\ttrain-rmse:0.08079\teval-rmse:0.07718\n",
      "[678]\ttrain-rmse:0.08041\teval-rmse:0.07682\n",
      "[679]\ttrain-rmse:0.08009\teval-rmse:0.07650\n",
      "[680]\ttrain-rmse:0.07975\teval-rmse:0.07617\n",
      "[681]\ttrain-rmse:0.07937\teval-rmse:0.07582\n",
      "[682]\ttrain-rmse:0.07906\teval-rmse:0.07552\n",
      "[683]\ttrain-rmse:0.07873\teval-rmse:0.07519\n",
      "[684]\ttrain-rmse:0.07839\teval-rmse:0.07487\n",
      "[685]\ttrain-rmse:0.07803\teval-rmse:0.07453\n",
      "[686]\ttrain-rmse:0.07773\teval-rmse:0.07424\n",
      "[687]\ttrain-rmse:0.07741\teval-rmse:0.07393\n",
      "[688]\ttrain-rmse:0.07705\teval-rmse:0.07359\n",
      "[689]\ttrain-rmse:0.07668\teval-rmse:0.07323\n",
      "[690]\ttrain-rmse:0.07636\teval-rmse:0.07293\n",
      "[691]\ttrain-rmse:0.07608\teval-rmse:0.07265\n",
      "[692]\ttrain-rmse:0.07576\teval-rmse:0.07235\n",
      "[693]\ttrain-rmse:0.07549\teval-rmse:0.07208\n",
      "[694]\ttrain-rmse:0.07518\teval-rmse:0.07178\n",
      "[695]\ttrain-rmse:0.07487\teval-rmse:0.07148\n",
      "[696]\ttrain-rmse:0.07457\teval-rmse:0.07118\n",
      "[697]\ttrain-rmse:0.07424\teval-rmse:0.07087\n",
      "[698]\ttrain-rmse:0.07396\teval-rmse:0.07061\n",
      "[699]\ttrain-rmse:0.07366\teval-rmse:0.07031\n",
      "[700]\ttrain-rmse:0.07336\teval-rmse:0.07003\n",
      "[701]\ttrain-rmse:0.07307\teval-rmse:0.06974\n",
      "[702]\ttrain-rmse:0.07279\teval-rmse:0.06949\n",
      "[703]\ttrain-rmse:0.07250\teval-rmse:0.06920\n",
      "[704]\ttrain-rmse:0.07217\teval-rmse:0.06888\n",
      "[705]\ttrain-rmse:0.07191\teval-rmse:0.06863\n",
      "[706]\ttrain-rmse:0.07163\teval-rmse:0.06835\n",
      "[707]\ttrain-rmse:0.07136\teval-rmse:0.06811\n",
      "[708]\ttrain-rmse:0.07108\teval-rmse:0.06783\n",
      "[709]\ttrain-rmse:0.07081\teval-rmse:0.06757\n",
      "[710]\ttrain-rmse:0.07054\teval-rmse:0.06730\n",
      "[711]\ttrain-rmse:0.07027\teval-rmse:0.06704\n",
      "[712]\ttrain-rmse:0.07000\teval-rmse:0.06678\n",
      "[713]\ttrain-rmse:0.06975\teval-rmse:0.06654\n",
      "[714]\ttrain-rmse:0.06948\teval-rmse:0.06627\n",
      "[715]\ttrain-rmse:0.06917\teval-rmse:0.06598\n",
      "[716]\ttrain-rmse:0.06893\teval-rmse:0.06576\n",
      "[717]\ttrain-rmse:0.06869\teval-rmse:0.06552\n",
      "[718]\ttrain-rmse:0.06840\teval-rmse:0.06524\n",
      "[719]\ttrain-rmse:0.06816\teval-rmse:0.06502\n",
      "[720]\ttrain-rmse:0.06791\teval-rmse:0.06477\n",
      "[721]\ttrain-rmse:0.06766\teval-rmse:0.06453\n",
      "[722]\ttrain-rmse:0.06742\teval-rmse:0.06429\n",
      "[723]\ttrain-rmse:0.06718\teval-rmse:0.06405\n",
      "[724]\ttrain-rmse:0.06694\teval-rmse:0.06382\n",
      "[725]\ttrain-rmse:0.06670\teval-rmse:0.06358\n",
      "[726]\ttrain-rmse:0.06646\teval-rmse:0.06336\n",
      "[727]\ttrain-rmse:0.06618\teval-rmse:0.06309\n",
      "[728]\ttrain-rmse:0.06596\teval-rmse:0.06288\n",
      "[729]\ttrain-rmse:0.06573\teval-rmse:0.06265\n",
      "[730]\ttrain-rmse:0.06546\teval-rmse:0.06240\n",
      "[731]\ttrain-rmse:0.06523\teval-rmse:0.06217\n",
      "[732]\ttrain-rmse:0.06502\teval-rmse:0.06197\n",
      "[733]\ttrain-rmse:0.06479\teval-rmse:0.06175\n",
      "[734]\ttrain-rmse:0.06456\teval-rmse:0.06153\n",
      "[735]\ttrain-rmse:0.06430\teval-rmse:0.06129\n",
      "[736]\ttrain-rmse:0.06410\teval-rmse:0.06110\n",
      "[737]\ttrain-rmse:0.06388\teval-rmse:0.06088\n",
      "[738]\ttrain-rmse:0.06363\teval-rmse:0.06065\n",
      "[739]\ttrain-rmse:0.06344\teval-rmse:0.06046\n",
      "[740]\ttrain-rmse:0.06323\teval-rmse:0.06026\n",
      "[741]\ttrain-rmse:0.06303\teval-rmse:0.06006\n",
      "[742]\ttrain-rmse:0.06281\teval-rmse:0.05985\n",
      "[743]\ttrain-rmse:0.06257\teval-rmse:0.05962\n",
      "[744]\ttrain-rmse:0.06233\teval-rmse:0.05939\n",
      "[745]\ttrain-rmse:0.06213\teval-rmse:0.05922\n",
      "[746]\ttrain-rmse:0.06193\teval-rmse:0.05902\n",
      "[747]\ttrain-rmse:0.06174\teval-rmse:0.05883\n",
      "[748]\ttrain-rmse:0.06154\teval-rmse:0.05863\n",
      "[749]\ttrain-rmse:0.06135\teval-rmse:0.05845\n",
      "[750]\ttrain-rmse:0.06115\teval-rmse:0.05826\n",
      "[751]\ttrain-rmse:0.06096\teval-rmse:0.05807\n",
      "[752]\ttrain-rmse:0.06073\teval-rmse:0.05786\n",
      "[753]\ttrain-rmse:0.06054\teval-rmse:0.05767\n",
      "[754]\ttrain-rmse:0.06036\teval-rmse:0.05750\n",
      "[755]\ttrain-rmse:0.06017\teval-rmse:0.05732\n",
      "[756]\ttrain-rmse:0.05999\teval-rmse:0.05714\n",
      "[757]\ttrain-rmse:0.05977\teval-rmse:0.05693\n",
      "[758]\ttrain-rmse:0.05958\teval-rmse:0.05676\n",
      "[759]\ttrain-rmse:0.05941\teval-rmse:0.05659\n",
      "[760]\ttrain-rmse:0.05921\teval-rmse:0.05640\n",
      "[761]\ttrain-rmse:0.05904\teval-rmse:0.05625\n",
      "[762]\ttrain-rmse:0.05886\teval-rmse:0.05607\n",
      "[763]\ttrain-rmse:0.05868\teval-rmse:0.05590\n",
      "[764]\ttrain-rmse:0.05849\teval-rmse:0.05572\n",
      "[765]\ttrain-rmse:0.05833\teval-rmse:0.05557\n",
      "[766]\ttrain-rmse:0.05815\teval-rmse:0.05540\n",
      "[767]\ttrain-rmse:0.05799\teval-rmse:0.05524\n",
      "[768]\ttrain-rmse:0.05782\teval-rmse:0.05507\n",
      "[769]\ttrain-rmse:0.05765\teval-rmse:0.05491\n",
      "[770]\ttrain-rmse:0.05748\teval-rmse:0.05475\n",
      "[771]\ttrain-rmse:0.05731\teval-rmse:0.05458\n",
      "[772]\ttrain-rmse:0.05715\teval-rmse:0.05443\n",
      "[773]\ttrain-rmse:0.05699\teval-rmse:0.05428\n",
      "[774]\ttrain-rmse:0.05679\teval-rmse:0.05409\n",
      "[775]\ttrain-rmse:0.05663\teval-rmse:0.05393\n",
      "[776]\ttrain-rmse:0.05648\teval-rmse:0.05380\n",
      "[777]\ttrain-rmse:0.05633\teval-rmse:0.05365\n",
      "[778]\ttrain-rmse:0.05617\teval-rmse:0.05350\n",
      "[779]\ttrain-rmse:0.05600\teval-rmse:0.05335\n",
      "[780]\ttrain-rmse:0.05584\teval-rmse:0.05320\n",
      "[781]\ttrain-rmse:0.05570\teval-rmse:0.05307\n",
      "[782]\ttrain-rmse:0.05555\teval-rmse:0.05292\n",
      "[783]\ttrain-rmse:0.05540\teval-rmse:0.05278\n",
      "[784]\ttrain-rmse:0.05525\teval-rmse:0.05263\n",
      "[785]\ttrain-rmse:0.05511\teval-rmse:0.05250\n",
      "[786]\ttrain-rmse:0.05497\teval-rmse:0.05236\n",
      "[787]\ttrain-rmse:0.05482\teval-rmse:0.05223\n",
      "[788]\ttrain-rmse:0.05467\teval-rmse:0.05208\n",
      "[789]\ttrain-rmse:0.05454\teval-rmse:0.05196\n",
      "[790]\ttrain-rmse:0.05440\teval-rmse:0.05183\n",
      "[791]\ttrain-rmse:0.05426\teval-rmse:0.05169\n",
      "[792]\ttrain-rmse:0.05412\teval-rmse:0.05155\n",
      "[793]\ttrain-rmse:0.05394\teval-rmse:0.05139\n",
      "[794]\ttrain-rmse:0.05378\teval-rmse:0.05124\n",
      "[795]\ttrain-rmse:0.05365\teval-rmse:0.05111\n",
      "[796]\ttrain-rmse:0.05351\teval-rmse:0.05099\n",
      "[797]\ttrain-rmse:0.05337\teval-rmse:0.05085\n",
      "[798]\ttrain-rmse:0.05324\teval-rmse:0.05072\n",
      "[799]\ttrain-rmse:0.05309\teval-rmse:0.05059\n",
      "[800]\ttrain-rmse:0.05296\teval-rmse:0.05046\n",
      "[801]\ttrain-rmse:0.05283\teval-rmse:0.05034\n",
      "[802]\ttrain-rmse:0.05270\teval-rmse:0.05022\n",
      "[803]\ttrain-rmse:0.05257\teval-rmse:0.05011\n",
      "[804]\ttrain-rmse:0.05242\teval-rmse:0.04996\n",
      "[805]\ttrain-rmse:0.05229\teval-rmse:0.04984\n",
      "[806]\ttrain-rmse:0.05216\teval-rmse:0.04972\n",
      "[807]\ttrain-rmse:0.05204\teval-rmse:0.04959\n",
      "[808]\ttrain-rmse:0.05192\teval-rmse:0.04949\n",
      "[809]\ttrain-rmse:0.05178\teval-rmse:0.04936\n",
      "[810]\ttrain-rmse:0.05165\teval-rmse:0.04924\n",
      "[811]\ttrain-rmse:0.05153\teval-rmse:0.04913\n",
      "[812]\ttrain-rmse:0.05141\teval-rmse:0.04901\n",
      "[813]\ttrain-rmse:0.05129\teval-rmse:0.04890\n",
      "[814]\ttrain-rmse:0.05117\teval-rmse:0.04879\n",
      "[815]\ttrain-rmse:0.05105\teval-rmse:0.04868\n",
      "[816]\ttrain-rmse:0.05094\teval-rmse:0.04856\n",
      "[817]\ttrain-rmse:0.05082\teval-rmse:0.04845\n",
      "[818]\ttrain-rmse:0.05069\teval-rmse:0.04834\n",
      "[819]\ttrain-rmse:0.05057\teval-rmse:0.04822\n",
      "[820]\ttrain-rmse:0.05046\teval-rmse:0.04812\n",
      "[821]\ttrain-rmse:0.05035\teval-rmse:0.04802\n",
      "[822]\ttrain-rmse:0.05024\teval-rmse:0.04791\n",
      "[823]\ttrain-rmse:0.05012\teval-rmse:0.04780\n",
      "[824]\ttrain-rmse:0.04999\teval-rmse:0.04768\n",
      "[825]\ttrain-rmse:0.04989\teval-rmse:0.04758\n",
      "[826]\ttrain-rmse:0.04978\teval-rmse:0.04748\n",
      "[827]\ttrain-rmse:0.04967\teval-rmse:0.04737\n",
      "[828]\ttrain-rmse:0.04956\teval-rmse:0.04727\n",
      "[829]\ttrain-rmse:0.04944\teval-rmse:0.04716\n",
      "[830]\ttrain-rmse:0.04933\teval-rmse:0.04706\n",
      "[831]\ttrain-rmse:0.04924\teval-rmse:0.04697\n",
      "[832]\ttrain-rmse:0.04911\teval-rmse:0.04685\n",
      "[833]\ttrain-rmse:0.04901\teval-rmse:0.04675\n",
      "[834]\ttrain-rmse:0.04890\teval-rmse:0.04665\n",
      "[835]\ttrain-rmse:0.04879\teval-rmse:0.04656\n",
      "[836]\ttrain-rmse:0.04867\teval-rmse:0.04645\n",
      "[837]\ttrain-rmse:0.04858\teval-rmse:0.04636\n",
      "[838]\ttrain-rmse:0.04845\teval-rmse:0.04624\n",
      "[839]\ttrain-rmse:0.04832\teval-rmse:0.04612\n",
      "[840]\ttrain-rmse:0.04823\teval-rmse:0.04603\n",
      "[841]\ttrain-rmse:0.04813\teval-rmse:0.04593\n",
      "[842]\ttrain-rmse:0.04803\teval-rmse:0.04584\n",
      "[843]\ttrain-rmse:0.04793\teval-rmse:0.04575\n",
      "[844]\ttrain-rmse:0.04784\teval-rmse:0.04566\n",
      "[845]\ttrain-rmse:0.04771\teval-rmse:0.04555\n",
      "[846]\ttrain-rmse:0.04763\teval-rmse:0.04546\n",
      "[847]\ttrain-rmse:0.04753\teval-rmse:0.04538\n",
      "[848]\ttrain-rmse:0.04743\teval-rmse:0.04528\n",
      "[849]\ttrain-rmse:0.04734\teval-rmse:0.04519\n",
      "[850]\ttrain-rmse:0.04724\teval-rmse:0.04510\n",
      "[851]\ttrain-rmse:0.04715\teval-rmse:0.04502\n",
      "[852]\ttrain-rmse:0.04702\teval-rmse:0.04490\n",
      "[853]\ttrain-rmse:0.04693\teval-rmse:0.04481\n",
      "[854]\ttrain-rmse:0.04683\teval-rmse:0.04472\n",
      "[855]\ttrain-rmse:0.04673\teval-rmse:0.04463\n",
      "[856]\ttrain-rmse:0.04664\teval-rmse:0.04455\n",
      "[857]\ttrain-rmse:0.04655\teval-rmse:0.04446\n",
      "[858]\ttrain-rmse:0.04647\teval-rmse:0.04438\n",
      "[859]\ttrain-rmse:0.04638\teval-rmse:0.04429\n",
      "[860]\ttrain-rmse:0.04628\teval-rmse:0.04421\n",
      "[861]\ttrain-rmse:0.04619\teval-rmse:0.04412\n",
      "[862]\ttrain-rmse:0.04610\teval-rmse:0.04404\n",
      "[863]\ttrain-rmse:0.04601\teval-rmse:0.04395\n",
      "[864]\ttrain-rmse:0.04592\teval-rmse:0.04388\n",
      "[865]\ttrain-rmse:0.04584\teval-rmse:0.04380\n",
      "[866]\ttrain-rmse:0.04576\teval-rmse:0.04372\n",
      "[867]\ttrain-rmse:0.04567\teval-rmse:0.04364\n",
      "[868]\ttrain-rmse:0.04558\teval-rmse:0.04355\n",
      "[869]\ttrain-rmse:0.04550\teval-rmse:0.04348\n",
      "[870]\ttrain-rmse:0.04542\teval-rmse:0.04341\n",
      "[871]\ttrain-rmse:0.04532\teval-rmse:0.04331\n",
      "[872]\ttrain-rmse:0.04523\teval-rmse:0.04323\n",
      "[873]\ttrain-rmse:0.04515\teval-rmse:0.04315\n",
      "[874]\ttrain-rmse:0.04506\teval-rmse:0.04307\n",
      "[875]\ttrain-rmse:0.04498\teval-rmse:0.04300\n",
      "[876]\ttrain-rmse:0.04490\teval-rmse:0.04293\n",
      "[877]\ttrain-rmse:0.04482\teval-rmse:0.04285\n",
      "[878]\ttrain-rmse:0.04472\teval-rmse:0.04276\n",
      "[879]\ttrain-rmse:0.04465\teval-rmse:0.04269\n",
      "[880]\ttrain-rmse:0.04458\teval-rmse:0.04262\n",
      "[881]\ttrain-rmse:0.04450\teval-rmse:0.04255\n",
      "[882]\ttrain-rmse:0.04442\teval-rmse:0.04248\n",
      "[883]\ttrain-rmse:0.04433\teval-rmse:0.04240\n",
      "[884]\ttrain-rmse:0.04426\teval-rmse:0.04233\n",
      "[885]\ttrain-rmse:0.04419\teval-rmse:0.04226\n",
      "[886]\ttrain-rmse:0.04412\teval-rmse:0.04220\n",
      "[887]\ttrain-rmse:0.04401\teval-rmse:0.04210\n",
      "[888]\ttrain-rmse:0.04395\teval-rmse:0.04204\n",
      "[889]\ttrain-rmse:0.04387\teval-rmse:0.04197\n",
      "[890]\ttrain-rmse:0.04381\teval-rmse:0.04191\n",
      "[891]\ttrain-rmse:0.04374\teval-rmse:0.04184\n",
      "[892]\ttrain-rmse:0.04366\teval-rmse:0.04177\n",
      "[893]\ttrain-rmse:0.04359\teval-rmse:0.04171\n",
      "[894]\ttrain-rmse:0.04351\teval-rmse:0.04163\n",
      "[895]\ttrain-rmse:0.04345\teval-rmse:0.04157\n",
      "[896]\ttrain-rmse:0.04338\teval-rmse:0.04151\n",
      "[897]\ttrain-rmse:0.04331\teval-rmse:0.04145\n",
      "[898]\ttrain-rmse:0.04322\teval-rmse:0.04137\n",
      "[899]\ttrain-rmse:0.04316\teval-rmse:0.04130\n",
      "[900]\ttrain-rmse:0.04309\teval-rmse:0.04124\n",
      "[901]\ttrain-rmse:0.04303\teval-rmse:0.04119\n",
      "[902]\ttrain-rmse:0.04296\teval-rmse:0.04112\n",
      "[903]\ttrain-rmse:0.04290\teval-rmse:0.04106\n",
      "[904]\ttrain-rmse:0.04283\teval-rmse:0.04100\n",
      "[905]\ttrain-rmse:0.04276\teval-rmse:0.04093\n",
      "[906]\ttrain-rmse:0.04270\teval-rmse:0.04088\n",
      "[907]\ttrain-rmse:0.04264\teval-rmse:0.04082\n",
      "[908]\ttrain-rmse:0.04257\teval-rmse:0.04077\n",
      "[909]\ttrain-rmse:0.04250\teval-rmse:0.04070\n",
      "[910]\ttrain-rmse:0.04244\teval-rmse:0.04064\n",
      "[911]\ttrain-rmse:0.04238\teval-rmse:0.04058\n",
      "[912]\ttrain-rmse:0.04230\teval-rmse:0.04051\n",
      "[913]\ttrain-rmse:0.04224\teval-rmse:0.04046\n",
      "[914]\ttrain-rmse:0.04218\teval-rmse:0.04040\n",
      "[915]\ttrain-rmse:0.04213\teval-rmse:0.04035\n",
      "[916]\ttrain-rmse:0.04207\teval-rmse:0.04029\n",
      "[917]\ttrain-rmse:0.04200\teval-rmse:0.04023\n",
      "[918]\ttrain-rmse:0.04193\teval-rmse:0.04017\n",
      "[919]\ttrain-rmse:0.04188\teval-rmse:0.04012\n",
      "[920]\ttrain-rmse:0.04182\teval-rmse:0.04006\n",
      "[921]\ttrain-rmse:0.04177\teval-rmse:0.04001\n",
      "[922]\ttrain-rmse:0.04171\teval-rmse:0.03996\n",
      "[923]\ttrain-rmse:0.04165\teval-rmse:0.03991\n",
      "[924]\ttrain-rmse:0.04160\teval-rmse:0.03986\n",
      "[925]\ttrain-rmse:0.04155\teval-rmse:0.03981\n",
      "[926]\ttrain-rmse:0.04149\teval-rmse:0.03976\n",
      "[927]\ttrain-rmse:0.04143\teval-rmse:0.03970\n",
      "[928]\ttrain-rmse:0.04138\teval-rmse:0.03965\n",
      "[929]\ttrain-rmse:0.04132\teval-rmse:0.03960\n",
      "[930]\ttrain-rmse:0.04126\teval-rmse:0.03955\n",
      "[931]\ttrain-rmse:0.04121\teval-rmse:0.03950\n",
      "[932]\ttrain-rmse:0.04116\teval-rmse:0.03945\n",
      "[933]\ttrain-rmse:0.04108\teval-rmse:0.03938\n",
      "[934]\ttrain-rmse:0.04103\teval-rmse:0.03933\n",
      "[935]\ttrain-rmse:0.04098\teval-rmse:0.03929\n",
      "[936]\ttrain-rmse:0.04093\teval-rmse:0.03924\n",
      "[937]\ttrain-rmse:0.04088\teval-rmse:0.03919\n",
      "[938]\ttrain-rmse:0.04082\teval-rmse:0.03914\n",
      "[939]\ttrain-rmse:0.04077\teval-rmse:0.03909\n",
      "[940]\ttrain-rmse:0.04073\teval-rmse:0.03905\n",
      "[941]\ttrain-rmse:0.04068\teval-rmse:0.03900\n",
      "[942]\ttrain-rmse:0.04061\teval-rmse:0.03894\n",
      "[943]\ttrain-rmse:0.04056\teval-rmse:0.03889\n",
      "[944]\ttrain-rmse:0.04052\teval-rmse:0.03886\n",
      "[945]\ttrain-rmse:0.04047\teval-rmse:0.03881\n",
      "[946]\ttrain-rmse:0.04042\teval-rmse:0.03877\n",
      "[947]\ttrain-rmse:0.04036\teval-rmse:0.03871\n",
      "[948]\ttrain-rmse:0.04031\teval-rmse:0.03866\n",
      "[949]\ttrain-rmse:0.04026\teval-rmse:0.03862\n",
      "[950]\ttrain-rmse:0.04022\teval-rmse:0.03858\n",
      "[951]\ttrain-rmse:0.04017\teval-rmse:0.03854\n",
      "[952]\ttrain-rmse:0.04012\teval-rmse:0.03848\n",
      "[953]\ttrain-rmse:0.04007\teval-rmse:0.03844\n",
      "[954]\ttrain-rmse:0.04003\teval-rmse:0.03840\n",
      "[955]\ttrain-rmse:0.03997\teval-rmse:0.03835\n",
      "[956]\ttrain-rmse:0.03992\teval-rmse:0.03830\n",
      "[957]\ttrain-rmse:0.03986\teval-rmse:0.03825\n",
      "[958]\ttrain-rmse:0.03982\teval-rmse:0.03821\n",
      "[959]\ttrain-rmse:0.03976\teval-rmse:0.03816\n",
      "[960]\ttrain-rmse:0.03972\teval-rmse:0.03812\n",
      "[961]\ttrain-rmse:0.03967\teval-rmse:0.03807\n",
      "[962]\ttrain-rmse:0.03963\teval-rmse:0.03803\n",
      "[963]\ttrain-rmse:0.03958\teval-rmse:0.03799\n",
      "[964]\ttrain-rmse:0.03952\teval-rmse:0.03793\n",
      "[965]\ttrain-rmse:0.03947\teval-rmse:0.03788\n",
      "[966]\ttrain-rmse:0.03943\teval-rmse:0.03784\n",
      "[967]\ttrain-rmse:0.03939\teval-rmse:0.03780\n",
      "[968]\ttrain-rmse:0.03934\teval-rmse:0.03776\n",
      "[969]\ttrain-rmse:0.03928\teval-rmse:0.03771\n",
      "[970]\ttrain-rmse:0.03924\teval-rmse:0.03768\n",
      "[971]\ttrain-rmse:0.03919\teval-rmse:0.03763\n",
      "[972]\ttrain-rmse:0.03915\teval-rmse:0.03759\n",
      "[973]\ttrain-rmse:0.03911\teval-rmse:0.03755\n",
      "[974]\ttrain-rmse:0.03906\teval-rmse:0.03750\n",
      "[975]\ttrain-rmse:0.03901\teval-rmse:0.03746\n",
      "[976]\ttrain-rmse:0.03897\teval-rmse:0.03742\n",
      "[977]\ttrain-rmse:0.03893\teval-rmse:0.03738\n",
      "[978]\ttrain-rmse:0.03889\teval-rmse:0.03735\n",
      "[979]\ttrain-rmse:0.03885\teval-rmse:0.03731\n",
      "[980]\ttrain-rmse:0.03880\teval-rmse:0.03726\n",
      "[981]\ttrain-rmse:0.03876\teval-rmse:0.03722\n",
      "[982]\ttrain-rmse:0.03871\teval-rmse:0.03718\n",
      "[983]\ttrain-rmse:0.03868\teval-rmse:0.03715\n",
      "[984]\ttrain-rmse:0.03863\teval-rmse:0.03711\n",
      "[985]\ttrain-rmse:0.03859\teval-rmse:0.03707\n",
      "[986]\ttrain-rmse:0.03855\teval-rmse:0.03703\n",
      "[987]\ttrain-rmse:0.03851\teval-rmse:0.03700\n",
      "[988]\ttrain-rmse:0.03848\teval-rmse:0.03696\n",
      "[989]\ttrain-rmse:0.03843\teval-rmse:0.03692\n",
      "[990]\ttrain-rmse:0.03839\teval-rmse:0.03688\n",
      "[991]\ttrain-rmse:0.03835\teval-rmse:0.03685\n",
      "[992]\ttrain-rmse:0.03831\teval-rmse:0.03681\n",
      "[993]\ttrain-rmse:0.03828\teval-rmse:0.03678\n",
      "[994]\ttrain-rmse:0.03825\teval-rmse:0.03675\n",
      "[995]\ttrain-rmse:0.03820\teval-rmse:0.03670\n",
      "[996]\ttrain-rmse:0.03816\teval-rmse:0.03667\n",
      "[997]\ttrain-rmse:0.03812\teval-rmse:0.03663\n",
      "[998]\ttrain-rmse:0.03808\teval-rmse:0.03659\n",
      "[999]\ttrain-rmse:0.03804\teval-rmse:0.03656\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'best_ntree_limit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\Desktop\\IPD CODE\\algorithm\\main.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IPD%20CODE/algorithm/main.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mtrain(params, dtrain, num_boost_round\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, evals\u001b[39m=\u001b[39meval_set, early_stopping_rounds\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose_eval\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IPD%20CODE/algorithm/main.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Predictions\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IPD%20CODE/algorithm/main.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(dtest, ntree_limit\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mbest_ntree_limit)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IPD%20CODE/algorithm/main.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Evaluation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IPD%20CODE/algorithm/main.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m mse \u001b[39m=\u001b[39m mean_squared_error(y_test, y_pred)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'best_ntree_limit'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert the datasets into DMatrix, which is a high-performance XGBoost data structure\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'max_depth': 4,\n",
    "    'alpha': 10,\n",
    "    'learning_rate': 0.01,\n",
    "}\n",
    "\n",
    "# Train the model with early stopping\n",
    "eval_set = [(dtrain, 'train'), (dval, 'eval')]\n",
    "model = xgb.train(params, dtrain, num_boost_round=1000, evals=eval_set, early_stopping_rounds=10, verbose_eval=True)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(dtest, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
